<!doctype html><html lang=en><head><title>Support vector machines</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.b0c81e8d5a19b7c855a22c50bdb6f3ed82d31ad8b723e6b49096e34f22acdbbb.css integrity="sha256-sMgejVoZt8hVoixQvbbz7YLTGti3I+a0kJbjTyKs27s="><link rel=icon type=image/png href=/images/author/image_al_hu15845133475761513827.jpg><meta property="og:url" content="https://alpopkes.com/posts/machine_learning/support_vector_machines/"><meta property="og:site_name" content="Anna-Lena Popkes"><meta property="og:title" content="Support vector machines"><meta property="og:description" content="I posted another notebook in my machine learning basics repository. This time, I took a detailed look at support vector machines. The blog post below contains the same content as the original notebook. You can run the notebook directly in your Browser using Binder.
1. What are support vector machines? Support vector machines (short: SVMs) are supervised machine learning models. They are the most prominent member of the class of kernel methods."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-04-13T00:00:00+00:00"><meta property="article:modified_time" content="2021-04-13T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Support vector machines"><meta name=twitter:description content="I posted another notebook in my machine learning basics repository. This time, I took a detailed look at support vector machines. The blog post below contains the same content as the original notebook. You can run the notebook directly in your Browser using Binder.
1. What are support vector machines? Support vector machines (short: SVMs) are supervised machine learning models. They are the most prominent member of the class of kernel methods."><meta name=description content="Support vector machines"><script>theme=localStorage.getItem("darkmode:color-scheme")||"system",theme=="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-posts kind-page" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid bg-secondary wrapper"><nav class="navbar navbar-expand-xl top-navbar shadow" id=top-navbar><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button>
<i data-feather=sidebar></i>
</button>
<a class=navbar-brand href=/><img src=/images/author/image_al_hu15845133475761513827.jpg id=logo alt=Logo>
Anna-Lena Popkes</a>
<button class="navbar-toggler navbar-light" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class=nav-item><a class=nav-link href=/#skills>Skills</a></li><li class=nav-item><a class=nav-link href=/#experiences>Experiences</a></li><li class=nav-item><a class=nav-link href=/#projects>Projects</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=/#projects>Projects</a>
<a class=dropdown-item href=/#appearances>Talks & Podcasts</a>
<a class=dropdown-item href=/#recent-posts>Recent Posts</a></div></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=theme-icon src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=theme-icon src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/author/image_al_hu15845133475761513827.jpg class=d-none id=main-logo alt=Logo>
<img src=/images/author/image_al_hu15845133475761513827.jpg class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts/ data-filter=all>Posts</a></li><div class=subtree><li><a class=list-link href=/posts/news/ title="Personal news">Personal news</a></li><li><a class=list-link href=/posts/my_path_to_ml/ title="My path to machine learning">My path to machine learning</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/books/> Books</a><ul><li><a class=list-link href=/posts/books/reading_list/ title="Personal reading List">Personal reading List</a></li><li><a class=list-link href=/posts/books/deep_work/ title="Deep work">Deep work</a></li></ul></li><li><i data-feather=minus-circle></i><a class="active list-link" href=/posts/machine_learning/> Machine Learning</a><ul class=active><li><a class=list-link href=/posts/machine_learning/bayesian_linear_regression/ title="Bayesian linear regression">Bayesian linear regression</a></li><li><a class=list-link href=/posts/machine_learning/kl_divergence/ title="KL Divergence">KL Divergence</a></li><li><a class=list-link href=/posts/machine_learning/principal_component_analysis/ title="Principal component analysis (PCA)">Principal component analysis (PCA)</a></li><li><a class="active list-link" href=/posts/machine_learning/support_vector_machines/ title="Support vector machines">Support vector machines</a></li><li><a class=list-link href=/posts/machine_learning/variational_inference/ title="Variational Inference">Variational Inference</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/python/> Python</a><ul><li><a class=list-link href=/posts/python/coding_with_kids/ title="Coding with kids">Coding with kids</a></li><li><a class=list-link href=/posts/python/mocking/ title=Mocking>Mocking</a></li><li><a class=list-link href=/posts/python/packaging_tools/ title="Packaging tools">Packaging tools</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/python/magical_universe/> Magical Universe</a><ul><li><a class=list-link href=/posts/python/magical_universe/day_1_start/ title=Start>Start</a></li><li><a class=list-link href=/posts/python/magical_universe/day_1_magical_universe/ title="The Tales of Castle Kilmere">The Tales of Castle Kilmere</a></li><li><a class=list-link href=/posts/python/magical_universe/day_1_first_post_oop/ title="Object-oriented programming">Object-oriented programming</a></li><li><a class=list-link href=/posts/python/magical_universe/day_2_types_of_methods/ title="Types of methods">Types of methods</a></li><li><a class=list-link href=/posts/python/magical_universe/day_3_type_annotations/ title="Type annotations">Type annotations</a></li><li><a class=list-link href=/posts/python/magical_universe/day_4_to_string_conversion/ title="To-string conversion">To-string conversion</a></li><li><a class=list-link href=/posts/python/magical_universe/day_5_decorators/ title=Decorators>Decorators</a></li><li><a class=list-link href=/posts/python/magical_universe/day_6_properties/ title=Properties>Properties</a></li><li><a class=list-link href=/posts/python/magical_universe/day_7_underscore_patterns/ title="Underscore patterns">Underscore patterns</a></li><li><a class=list-link href=/posts/python/magical_universe/day_8_extending_universe/ title="Extending the universe">Extending the universe</a></li><li><a class=list-link href=/posts/python/magical_universe/day_9_duck_typing/ title="Duck Typing">Duck Typing</a></li><li><a class=list-link href=/posts/python/magical_universe/day_10_11_namedtuples/ title=Namedtuples>Namedtuples</a></li><li><a class=list-link href=/posts/python/magical_universe/day_12_to_15_abcs/ title="Abstract Base Classes">Abstract Base Classes</a></li><li><a class=list-link href=/posts/python/magical_universe/day_16_to_18_data_classes/ title="Data classes">Data classes</a></li><li><a class=list-link href=/posts/python/magical_universe/day_19_immutable_data_classes/ title="Immutable data classes">Immutable data classes</a></li><li><a class=list-link href=/posts/python/magical_universe/day_20_decorators_in_classes/ title="Decorators in classes">Decorators in classes</a></li><li><a class=list-link href=/posts/python/magical_universe/day_21_if_main/ title='if __name__ == "__main__"'>if __name__ == "__main__"</a></li><li><a class=list-link href=/posts/python/magical_universe/day_22_to_24_context_managers/ title="Context managers">Context managers</a></li><li><a class=list-link href=/posts/python/magical_universe/day_25_to_28_pytest/ title="Testing with pytest">Testing with pytest</a></li><li><a class=list-link href=/posts/python/magical_universe/day_29_to_31_iterators/ title=Iterators>Iterators</a></li><li><a class=list-link href=/posts/python/magical_universe/day_34_multisets/ title=Multisets>Multisets</a></li><li><a class=list-link href=/posts/python/magical_universe/day_37_extending_universe/ title="Extending the universe II">Extending the universe II</a></li><li><a class=list-link href=/posts/python/magical_universe/day_43_to_45_exception_classes/ title="Exception classes">Exception classes</a></li><li><a class=list-link href=/posts/python/magical_universe/day_46_functools_wraps/ title=functools.wraps>functools.wraps</a></li><li><a class=list-link href=/posts/python/magical_universe/day_47_to_48_defaultdict/ title=Defaultdict>Defaultdict</a></li><li><a class=list-link href=/posts/python/magical_universe/day_49_to_50_config_files/ title="Config files">Config files</a></li><li><a class=list-link href=/posts/python/magical_universe/2018-09-16-blog-post-day-51/ title="Wrap up">Wrap up</a></li></ul></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/software_engineering/> Software Engineering</a><ul><li><a class=list-link href=/posts/software_engineering/containers/ title="Intro to containers">Intro to containers</a></li><li><a class=list-link href=/posts/software_engineering/docker/ title="Intro to Docker">Intro to Docker</a></li><li><a class=list-link href=/posts/software_engineering/virtual_machines/ title="Intro to virtual machines">Intro to virtual machines</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ms-auto align-self-lg-center"><img class=rounded-circle src=/images/author/image_al_hu6187147171234605626.jpg alt="Author Image"><h5 class=author-name>Anna-Lena Popkes</h5><p class=text-muted>Tuesday, April 13, 2021</p></div><div class=title><h1>Support vector machines</h1></div><div class=post-content id=post-content><p>I posted another notebook in my <a href=https://github.com/zotroneneis/machine_learning_basics target=_blank rel=noopener>machine learning basics repository</a>. This time, I took a detailed look at support vector machines. The blog post below contains the same content as the <a href=https://github.com/zotroneneis/machine_learning_basics/blob/master/support_vector_machines.ipynb target=_blank rel=noopener>original notebook</a>. You can <a href="https://mybinder.org/v2/gh/zotroneneis/machine_learning_basics/HEAD?filepath=support_vector_machines.ipynb" target=_blank rel=noopener>run the notebook directly in your Browser using Binder</a>.</p><h2 id=1-what-are-support-vector-machines>1. What are support vector machines?</h2><p>Support vector machines (short: SVMs) are supervised machine learning models. They are the most prominent member of the class of <a href=https://en.wikipedia.org/wiki/Kernel_method target=_blank rel=noopener><em>kernel methods</em></a>. SVMs can be used both for classification and regression. The original SVM proposed in 1963 is a simple binary linear classifier. What does this mean?</p><p>Assume we are given a dataset $D = \big \{ \mathbf{x}_n, y_n \big \}_{n=1}^N$, where $\mathbf{x} \in \mathbb{R}^D$ and labels $y_n \in {-1, +1 }$. A linear (hard-margin) SVM separates the two classes using a ($D-1$ dimensional) hyperplane.</p><p>Special to SVMs is that they use not any hyperplane but the one that maximizes the distance between itself and the two sets of datapoints. Such a hyperplane is called <em>maximum-margin</em> hyperplane:</p><img src=/posts/machine_learning/images/separating_hyperplanes.png width=60% class=center><p>In case you have never heard the term margin: the margin describes the distance between the hyperplane and the closest examples in the dataset.</p><p>Two types of SVMs exist: primals SVMs and dual SVMs. Although most research in the past looked into dual SVMs both can be used to perform non-linear classification. Therefore, we will look at both approaches and compare them in the end.</p><h2 id=2-primal-approach---hard-margin-svm>2. Primal approach - Hard-margin SVM</h2><p>When training an SVM our goal is to find the hyperplane that maximizes the margin between the two sets of points. This hyperplane is fully defined by the points closest to the margin, which are also called <em>support vectors</em>.</p><p>The equation of a hyperplane is given by $\langle \mathbf{w}, \mathbf{x} \rangle + b = 0$. If an example $\mathbf{x}_i$ lies on the right side of the hyperplane (that is, it has a positive label) we have $\langle \mathbf{w}, \mathbf{x} \rangle + b \gt 0$. If instead $\mathbf{x}_i$ lies on the left side (= negative label) we have $\langle \mathbf{w}, \mathbf{x} \rangle + b \lt 0$.</p><p>The support vectors lie exactly on the margin and the optimal separating hyperplane should have the same distance from all support vectors. In this sense the maximum margin hyperplane lies between two separating hyperplanes that are determined by the support vectors:</p><img src=/posts/machine_learning/images/delimiting_hyperplanes.png width=40% class=center><h3 id=21-goal-1>2.1 Goal 1</h3><p>When deriving a formal equation for the maximum margin hyperplane we assume that the two delimiting hyperplanes are given by:<br>$$\langle \mathbf{w}, \mathbf{x}_{+} \rangle + b = +1$$
$$\langle \mathbf{w}, \mathbf{x}_{-} \rangle + b = -1$$</p><p>In other words: we want our datapoints two lie at least a distance of 1 away from the decision hyperplane into both directions. To be more precise: for our positive examples (those with label $y_n = +1$) we want the following to hold: $\langle \mathbf{w}, \mathbf{x}_n \rangle + b \ge +1$.</p><p>For our negative examples (those with label $y_n = -1$) we want the opposite: $\langle \mathbf{w}, \mathbf{x}_n \rangle + b \le -1$. This can be combined into a single equation: $y_n(\langle \mathbf{w}, \mathbf{x}_n \rangle + b) \ge 1$. This is our first goal: <strong>We want a decision boundary that classifies our training examples correctly.</strong></p><h3 id=22-goal-2>2.2 Goal 2</h3><p>Our second goal is to maximize the margin of this decision boundary. The margin is given by $\frac{1}{\mathbf{w}}$. If you would like to understand where this value is coming from take a look at the section &ldquo;<em>(Optional) Deriving the margin equation</em>&rdquo; below.</p><p>Our goal to maximize the margin can be expressed as follows:
$$ \max_{\mathbf{w}, b} \frac{1}{\Vert \mathbf{w} \Vert}$$</p><p>Instead of maximizing $\frac{1}{\Vert \mathbf{w} \Vert}$ we can instead minimize $\frac{1}{2} \Vert \mathbf{w} \Vert^2$. This simplifies the computation of the gradient.</p><h3 id=23-combined-goal>2.3 Combined goal</h3><p>Combining goal one and goal two yields the following objective function:<br>$$
\min_{\mathbf{w}, b} \frac{1}{2} \Vert \mathbf{w} \Vert^2
$$
$$
\text{subject to: } y_n(\langle \mathbf{w}, \mathbf{x}_n \rangle + b) \ge 1 \text{ for all } n = 1, &mldr;, N
$$</p><p>In words: we want to find the values for $\mathbf{w}$ and $b$ that maximize the margin while classifying all training examples correctly. This approach is called the <em>hard-margin support vector machine</em>. &ldquo;Hard&rdquo; because it does not allow for violations of the margin requirement (= no points are allowed to be within the margin).</p><h3 id=24-optional-deriving-the-margin-equation>2.4 (Optional) Deriving the margin equation</h3><p>We can derive the width of the margin in several ways (see sections 12.2.1-12.2.2 of the <a href=https://mml-book.com target=_blank rel=noopener>Mathematics for Machine Learning book</a>). Personally, I found the explanation of <a href="https://www.youtube.com/watch?v=_PwhiWxHK8o" target=_blank rel=noopener>this MIT lecture on SVMs</a> easiest to understand.</p><p>The derivation of the margin is based on the assumptions that we have already noted above:
$$\langle \mathbf{w}, \mathbf{x}_{+} \rangle + b = +1$$
$$\langle \mathbf{w}, \mathbf{x}_{-} \rangle + b = -1$$</p><p>Including the label of each example we can rewrite this as
$$y_i (\langle \mathbf{w}, \mathbf{x}_{i} \rangle + b) -1 = 0$$</p><p>Let&rsquo;s say we have a positive example $\mathbf{x}_{+}$ that lies on the right delimiting hyperplane and a negative example $\mathbf{x}_{-}$ that lies on the left delimiting hyperplane. The distance between these two vectors is given by ($\mathbf{x}_{+} - \mathbf{x}_{-})$. We want to compute the orthogonal projection of the vector onto the line that is perpendicular to the decision hyperplane. This would give us the width between the two delimiting hyperplanes. We can compute this by multiplying the vector ($\mathbf{x}_{+} - \mathbf{x}_{-})$ with a vector that is perpendicular to the hyperplane. We know that the vector $\mathbf{w}$ is perpendicular to the decision hyperplane. So we can compute the margin by multiplying $(\mathbf{x}_{+} - \mathbf{x}_{-})$ with the vector $\mathbf{w}$ where the latter is divided by the scale $||\mathbf{w}||$ to make it a unit vector.</p><img src=/posts/machine_learning/images/maximum_margin_derivation.png width=40% class=center><p>$$
\begin{align}
\text{width} &= (\mathbf{x}_{+} - \mathbf{x}_{-}) \cdot \frac{\mathbf{w}}{||\mathbf{w}||} \\\
&= \frac{\mathbf{x}_{+} \cdot \mathbf{w}}{||\mathbf{w}||} - \frac{\mathbf{x}_{-} \cdot \mathbf{w}}{||\mathbf{w}||}
\end{align}
$$</p><p>For the positive example $\mathbf{x}_{+}$ we have $y_+ = +1$ and therefore $(\langle \mathbf{w}, \mathbf{x}_{+} \rangle = 1 - b$. For the negative example $\mathbf{x}_{-}$ we have $y_- = -1$ and therefore $- (\langle \mathbf{w}, \mathbf{x}_{-} \rangle) = 1 + b$:</p><p>$$
\begin{align}
\text{width} &= (\mathbf{x}_{+} - \mathbf{x}_{-}) \cdot \frac{\mathbf{w}}{||\mathbf{w}||} \\\
&= \frac{\mathbf{x}_{+} \cdot \mathbf{w}}{||\mathbf{w}||} - \frac{\mathbf{x}_{-} \cdot \mathbf{w}}{||\mathbf{w}||} \\\
&= \frac{(1 - b) + (1 + b)}{||\mathbf{w}||}\\\
&= \frac{2}{||\mathbf{w}||}\\\
\end{align}
$$</p><p>We conclude that the width between the two delimiting hyperplanes equals $\frac{2}{\mathbf{w}}$. And therefore, that the distance between the decision hyperplane and each delimiting hyperplane is $\frac{1}{\mathbf{w}}$.</p><h2 id=3-primal-approach---soft-margin-svm>3. Primal approach - Soft-margin SVM</h2><p>In most real-world situations the available data is not linearly separable. Even if it is, we might prefer a solution which separates the data well while ignoring some noisy examples and outliers. This motivated an extension of the original hard-margin SVM called <em>soft-margin SVM</em>.</p><p>A soft-margin SVM allows for violations of the margin requirement (= classification errors). In other words: not all training examples need to be perfectly classified. They might fall within the margin or even lie on the wrong side of the decision hyperplane. However, such violations are not for free. We pay a cost for each violation, where the value of the cost depends on how far the example is from meeting the margin requirement.</p><p>To implement this we introduce so called <em>slack variables</em> $\xi_n$. Each training example $(\mathbf{x}_n, y_n)$ is assigned a slack variable $\xi_n \ge 0$. The slack variable allows this example to be within the margin or even on the wrong side of the decision hyperplane:</p><ul><li>If $\xi_n = 0$ the training example $(\mathbf{x}_n, y_n)$ lies exactly on the margin</li><li>$0 \lt \xi_n \lt 1$ the training example lies within the margin but on the correct side of the decision hyperplane</li><li>$\xi_n \ge 1$ the training example lies on the wrong side of the decision hyperplane</li></ul><p>We extend our objective function to include the slack variables as follows:
$$ \min_{\mathbf{w}, b, \mathbf{\xi}} \frac{1}{2} \Vert \mathbf{w} \Vert^2 + C \sum_{n=1}^N \xi_n $$</p><p>$$ \text{subject to:} $$</p><p>$$ \begin{equation}
y_n(\langle \mathbf{w}, \mathbf{x}_n \rangle + b) \ge 1 - \xi_n
\end{equation}$$</p><p>$$ \xi_i \gt 0 \text{ for all } n = 1, &mldr;, N $$</p><p>The parameter $C$ is a regularization term that controls the trade-off between maximizing the margin and minimizing the training error (which in turn means classifying all training examples correctly). If the value of $C$ is small, we care more about maximizing the margin than classifying all points correctly. If the value of $C$ is large, we care more about classifying all points correctly than maximizing the margin.</p><h2 id=4-solving-the-primal-optimization-problem>4. Solving the primal optimization problem</h2><p>Theoretically, the primal SVM can be solved in multiple ways. The most well known way is to use the <a href=https://en.wikipedia.org/wiki/Hinge_loss target=_blank rel=noopener>hinge loss function</a> together with <a href=https://en.wikipedia.org/wiki/Subgradient_method target=_blank rel=noopener>subgradient descent</a>.</p><h3 id=41-hinge-loss-function>4.1 Hinge loss function</h3><p>The hinge loss function given the true target $y \in {-1, +1}$ and the prediction $f(\mathbf{x}) = \langle\mathbf{w}, \mathbf{x}\rangle+b$ is computed as follows:</p><p>$$\ell(t)=\max {0,1-t} \quad \text{where} \quad t=y \cdot f(\mathbf{x})= y \cdot \big(\langle\mathbf{w}, \mathbf{x}\rangle+b\big)$$</p><p>Let&rsquo;s understand the output of this loss function with a few examples:</p><ul><li>If a training example has label $y = -1$ and the prediction is on the correct side of the marghin (that is, $f(\mathbf{x}) \le -1$), the value of $t$ is larger or equal to $+1$. Therefore, the hinge loss will be zero ($\ell(t) = 0$)</li><li>The same holds if a training example has label $y = 1$ and the prediction is on the correct side of the margin (that is, $f(\mathbf{x}) \ge 1$)</li><li>If a training example ($y = 1$) is on the correct side of the decision hyperplane but lies within the margin (that is, $0 \lt f(\mathbf{x}) \lt 1$) the hinge loss will output a positive value.</li><li>If a training example ($y = 1$) is on the wrong side of the decision hyperplane (that is, $f(\mathbf{x}) \lt 0$), the hinge loss returns an even larger value. This value increases linearly with the distance from the decision hyperplane</li></ul><img src=/posts/machine_learning/images/hinge_loss.png width=50% class=center><h3 id=42-updated-objective-function>4.2 Updated objective function</h3><p>Using the hinge loss we can reformulate the optimization problem of the primal soft-margin SVM. Given a dataset $D = \big \{ \mathbf{x}_n, y_n \big \}_{n=1}^N$ we would like to minimize the total loss which is now given by:</p><p>$$
\min_{\mathbf{w}, b} \frac{1}{2}|\mathbf{w}|^{2} + C \sum_{n=1}^{N} \max \left\{0,1-y_{n}\left(\left\langle\mathbf{w}, \mathbf{x}_{n}\right\rangle+b\right)\right\}
$$</p><p>If you would like to understand why this is equivalent to our previous formulation of the soft-margin SVM please take a look at chapter 12.2.5 of the <a href=https://mml-book.com target=_blank rel=noopener>Mathematics for Machine Learning book</a>.</p><h3 id=43-optional-three-parts-of-the-objective-function>4.3 [Optional] Three parts of the objective function</h3><p>Our objective function can be divided into three distinct parts:</p><p>Part 1: $\frac{1}{2}|\mathbf{w}|^{2}$</p><p>This part is also called the <em>regularization term</em>. It expresses a preference for solutions that separate the datapoints well, thereby maximizing the margin. In theory, we could replace this term by a different regularization term that expresses a different preference.</p><p>Part 2: $\sum_{n=1}^{N} \max \left\{0,1-y_{n}\left(\left\langle\mathbf{w}, \mathbf{x}_{n}\right\rangle+b\right)\right\}$</p><p>This part is also called the <em>empirical loss</em>. In our case it&rsquo;s the hinge loss which penalizes solutions that make mistakes when classifying the training examples. In theory, this term could be replaced with another loss function that expresses a different preference.</p><p>Part 3: The hyperparameter $C$ that controls the tradeoff between a large margin and a small hinge loss.</p><h3 id=44-sub-gradient-descent>4.4 Sub-gradient descent</h3><p>The hinge loss function is not differentiable (namely at the point $t=1$). Therefore, we cannot compute the gradient right away. However, we can use a method called <a href=https://en.wikipedia.org/wiki/Subgradient_method target=_blank rel=noopener>subgradient descent</a> to solve our optimization problem. To simplify the derivation we will adapt two things:</p><ol><li>We assume that the bias $b$ is contained in our weight vector as the first entry $w_0$, that is $\mathbf{w} = [b, w_1, &mldr;, w_D]$</li><li>We divide the hinge loss by the number of samples</li></ol><p>Our cost function is then given by
$$
J(\mathbf{w}) = \frac{1}{2}|\mathbf{w}|^{2} + C \frac{1}{N} \sum_{n=1}^{N} \max \left\{0,1-y_{n}\left(\left\langle\mathbf{w}, \mathbf{x}_{n}\right\rangle\right)\right\}
$$</p><p>We will reformulate this to simplify computing the gradient:
$$
J(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^{N} \Big \{ \frac{1}{2}|\mathbf{w}|^{2} + C \max \left\{0,1-y_{n}\left(\left\langle\mathbf{w}, \mathbf{x}_{n}\right\rangle\right)\right\} \Big\}
$$</p><p>The gradient is given by:
$$
\nabla_{w} J(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^N \left\{\begin{array}{ll}
\mathbf{w} & \text{if} \max \left(0,1-y_{n} \left(\langle \mathbf{w}, \mathbf{x}_{n} \rangle \right)\right)=0 \\\
\mathbf{w}-C y_{n} \mathbf{x}_{n} & \text { otherwise }
\end{array}\right \}.
$$</p><p>With this formula we can apply stochastic gradient descent to solve the optimization problem.</p><h3 id=45-optional-difference-subgradient-descent-and-gradient-descent>4.5 [Optional] Difference subgradient descent and gradient descent</h3><p>The subgradient method allows us to minimize a non-differentiable convex function. Although looking similar to gradient descent the method has several important differences.</p><h4 id=451-what-is-a-subgradient>4.5.1 What is a subgradient?</h4><p>A subgradient can be described as a generalization of gradients to non-differentiable functions. Informally, a sub-tangent at a point is any line that lies below the function at the point. The subgradient is the slope of this line. Formally, the subgradient a convex function $f$ at $w_0$ is defined as all vectors $g$ such that for any other point $w$</p><p>$$ f(w) - f(w_0) \ge g \cdot (w - w_0) $$</p><p>If $f$ is differentiable at $w_0$, the subgradient contains only one vector which equals the gradient $\nabla f(w_0)$. If, however, $f$ is not differentiable, there may be several values for $g$ that satisfy this inequality. This is illustrated in the figure below.</p><img src=/posts/machine_learning/images/gradient_vs_subgradient.png width=65% class=center><h4 id=452-subgradient-method>4.5.2 Subgradient method</h4><p>To minimize the objective function $f$ the subgradient method uses the following update formula for iteration $k+1$:</p><p>$$ w^{(k+1)} = w^{(k)} - \alpha_k g^{(k)}$$</p><p>Where $g^{(k)}$ is <em>any</em> subgradient of $f$ at $w^{(k)}$ and $\alpha_k$ is the $k$-th step size. Thus, at each iteration, we make a step into the direction of the negative subgradient. When $f$ is differentiable, $g^{(k)}$ equals the gradient $\nabla f(x^{(k)})$ and the method reduces to the standard gradient descent method.</p><p>More details on the subgradient method can be found <a href=https://web.stanford.edu/class/ee392o/subgrad_method.pdf target=_blank rel=noopener>here</a>.</p><h2 id=5-implementation-primal-approach>5. Implementation primal approach</h2><h3 id=51-toy-dataset>5.1 Toy dataset</h3><p>To implement what we have learned about primal SVMs we first have to generate a dataset. In the cell below we create a simple dataset with two features and labels +1 and -1. We further split the dataset into a test and train set.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.datasets <span style=color:#f92672>import</span> make_blobs
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>features, targets <span style=color:#f92672>=</span> make_blobs(n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>600</span>, centers<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, n_features<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The function outputs targets 0 and 1 so we need to convert targets 0 to -1</span>
</span></span><span style=display:flex><span>transformed_targets <span style=color:#f92672>=</span> [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span> <span style=color:#66d9ef>if</span> t <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>else</span> <span style=color:#f92672>+</span><span style=color:#ae81ff>1</span> <span style=color:#66d9ef>for</span> t <span style=color:#f92672>in</span> targets]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span><span style=color:#75715e># Plot the dataset</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(features[:, <span style=color:#ae81ff>0</span>], features[:, <span style=color:#ae81ff>1</span>], c <span style=color:#f92672>=</span> transformed_targets)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Toy dataset&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Feature 2&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Feature 1&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Split data into training and test set</span>
</span></span><span style=display:flex><span>features_train, features_test, labels_train, labels_test <span style=color:#f92672>=</span> train_test_split(features, 
</span></span><span style=display:flex><span>                                                                              transformed_targets, 
</span></span><span style=display:flex><span>                                                                              test_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.3</span>)
</span></span></code></pre></div><img src=/posts/machine_learning/images/svm_dataset.png width=55% class=center><h3 id=52-svm-class-definition>5.2 SVM class definition</h3><p>Next, we would like to implement an SVM class. We will use the knowledge we already acquired:</p><ol><li>Our objective function using the hinge loss function is given by:
$$
J(\mathbf{w}) = \frac{1}{2}|\mathbf{w}|^{2} + C \frac{1}{N} \sum_{n=1}^{N} \max \left\{0,1-y_{n}\left(\left\langle\mathbf{w}, \mathbf{x}_{n}\right\rangle\right)\right\}
$$</li><li>We can minimize this function by computing the gradient:
$$
\nabla_{w} J(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^N \left \{ \begin{array}{ll}
\mathbf{w} & \text{if} \max \left(0,1-y_{n} \left(\langle \mathbf{w}, \mathbf{x}_{n} \rangle \right)\right)=0 \\\
\mathbf{w}-C y_{n} \mathbf{x}_{n} & \text { otherwise }
\end{array} \right \}.
$$</li><li>Given the gradient we use stochastic gradient descent to train our model</li><li>After training our model we can make predictions using the <a href=https://en.wikipedia.org/wiki/Sign_function target=_blank rel=noopener>sign function</a></li></ol><p>As mentioned previously, we will assume that the bias $b$ is contained in our weight vector as the first entry $w_0$, that is $\mathbf{w} = [b, w_1, &mldr;, w_D] = \mathbf{w} = [w_0, w_1, &mldr;, w_D]$.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.utils <span style=color:#f92672>import</span> shuffle
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LinearSVM</span>:
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, regularization_param):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Initialize the model by setting the regularization parameter 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        and a boolean variable for our trained weights.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>regularization_param <span style=color:#f92672>=</span> regularization_param
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>trained_weights <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>add_bias_term</span>(self, features):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Add intercept 1 to each training example for bias b
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        n_samples <span style=color:#f92672>=</span> features<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        ones <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>ones((n_samples, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>concatenate((ones, features), axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_cost</span>(self, weights, features, labels) <span style=color:#f92672>-&gt;</span> float:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Compute the value of the cost function
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        n_samples <span style=color:#f92672>=</span> features<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Compute hinge loss </span>
</span></span><span style=display:flex><span>        predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(features, weights)<span style=color:#f92672>.</span>flatten()
</span></span><span style=display:flex><span>        distances <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> labels <span style=color:#f92672>*</span> predictions
</span></span><span style=display:flex><span>        hinge_losses <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>maximum(<span style=color:#ae81ff>0</span>, distances)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Compute sum of the individual hinge losses</span>
</span></span><span style=display:flex><span>        sum_hinge_loss <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sum(hinge_losses) <span style=color:#f92672>/</span> n_samples
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Compute entire cost</span>
</span></span><span style=display:flex><span>        cost <span style=color:#f92672>=</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>dot(weights<span style=color:#f92672>.</span>T, weights) <span style=color:#f92672>+</span> self<span style=color:#f92672>.</span>regularization_param <span style=color:#f92672>*</span> sum_hinge_loss
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> float(cost)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>compute_gradient</span>(self, weights, features, labels) <span style=color:#f92672>-&gt;</span> np<span style=color:#f92672>.</span>ndarray:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Compute the gradient, needed for training
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        predictions <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>dot(features, weights)
</span></span><span style=display:flex><span>        distances <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> labels <span style=color:#f92672>*</span> predictions
</span></span><span style=display:flex><span>        n_samples, n_feat <span style=color:#f92672>=</span> features<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>        sub_gradients <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((<span style=color:#ae81ff>1</span>, n_feat))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> idx, dist <span style=color:#f92672>in</span> enumerate(distances):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> max(<span style=color:#ae81ff>0</span>, dist) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>                sub_gradients <span style=color:#f92672>+=</span> weights<span style=color:#f92672>.</span>T
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                sub_grad <span style=color:#f92672>=</span> weights<span style=color:#f92672>.</span>T <span style=color:#f92672>-</span> (self<span style=color:#f92672>.</span>regularization_param <span style=color:#f92672>*</span> features[idx] <span style=color:#f92672>*</span> labels[idx])
</span></span><span style=display:flex><span>                sub_gradients <span style=color:#f92672>+=</span> sub_grad
</span></span><span style=display:flex><span>                            
</span></span><span style=display:flex><span>        <span style=color:#75715e># Sum up and divide by the number of samples</span>
</span></span><span style=display:flex><span>        avg_gradient <span style=color:#f92672>=</span> sum(sub_gradients) <span style=color:#f92672>/</span> len(labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> avg_gradient
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train</span>(self, train_features, train_labels, n_epochs, learning_rate<span style=color:#f92672>=</span><span style=color:#ae81ff>0.01</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Train the model with stochastic gradient descent using the
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        specified number of epochs, learning rate and batch size.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Add bias term to features</span>
</span></span><span style=display:flex><span>        train_features <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>add_bias_term(train_features)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Initalize weight vector</span>
</span></span><span style=display:flex><span>        n_samples, n_feat <span style=color:#f92672>=</span> train_features<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>        weights <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros(n_feat)[:, np<span style=color:#f92672>.</span>newaxis]
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># Train the model for a certain number of epochs</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(n_epochs):
</span></span><span style=display:flex><span>            features, labels <span style=color:#f92672>=</span> shuffle(train_features, train_labels)
</span></span><span style=display:flex><span>            features, labels <span style=color:#f92672>=</span> train_features, train_labels
</span></span><span style=display:flex><span>            start, end <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, batch_size
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>while</span> end <span style=color:#f92672>&lt;=</span> len(labels): <span style=color:#75715e># Training loop over the dataset</span>
</span></span><span style=display:flex><span>                batch <span style=color:#f92672>=</span> features[start:end]
</span></span><span style=display:flex><span>                batch_labels <span style=color:#f92672>=</span> labels[start:end]
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>                grad <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>compute_gradient(weights, batch, batch_labels)
</span></span><span style=display:flex><span>                update <span style=color:#f92672>=</span> (learning_rate <span style=color:#f92672>*</span> grad)[:, np<span style=color:#f92672>.</span>newaxis]
</span></span><span style=display:flex><span>                weights <span style=color:#f92672>=</span> weights <span style=color:#f92672>-</span> update
</span></span><span style=display:flex><span>                start, end <span style=color:#f92672>=</span> end, end <span style=color:#f92672>+</span> batch_size
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>            current_cost <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>compute_cost(weights, features, labels)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, cost: </span><span style=color:#e6db74>{</span>current_cost<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>        <span style=color:#75715e># Set the trained weights to allow making predictions</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>trained_weights <span style=color:#f92672>=</span> weights
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>predict</span>(self, test_features) <span style=color:#f92672>-&gt;</span> np<span style=color:#f92672>.</span>ndarray:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Predict labels for new test features.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Raises ValueError if model has not been trained yet.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>        test_features <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>add_bias_term(test_features)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>trained_weights <span style=color:#f92672>is</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;You haven&#39;t trained the SVM yet!&#34;</span>)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        predicted_labels <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        n_samples <span style=color:#f92672>=</span> test_features<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> idx <span style=color:#f92672>in</span> range(n_samples):
</span></span><span style=display:flex><span>            prediction <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>sign(np<span style=color:#f92672>.</span>dot(self<span style=color:#f92672>.</span>trained_weights<span style=color:#f92672>.</span>T, test_features[idx]))
</span></span><span style=display:flex><span>            predicted_labels<span style=color:#f92672>.</span>append(prediction)
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> np<span style=color:#f92672>.</span>array(predicted_labels)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Compute some values to make sure the cost is computed correctly</span>
</span></span><span style=display:flex><span><span style=color:#75715e># I calculated the values for this example by hand first</span>
</span></span><span style=display:flex><span>svm <span style=color:#f92672>=</span> LinearSVM(regularization_param<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>weights <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>])[:, np<span style=color:#f92672>.</span>newaxis]
</span></span><span style=display:flex><span>features <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>0.5</span>], [<span style=color:#ae81ff>2.5</span>]])
</span></span><span style=display:flex><span>new_features <span style=color:#f92672>=</span> svm<span style=color:#f92672>.</span>add_bias_term(features)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>labels <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span><span style=color:#66d9ef>assert</span> svm<span style=color:#f92672>.</span>compute_cost(weights, new_features, labels) <span style=color:#f92672>==</span> <span style=color:#ae81ff>4.</span>
</span></span><span style=display:flex><span>gradient <span style=color:#f92672>=</span> svm<span style=color:#f92672>.</span>compute_gradient(weights, new_features, labels[:, np<span style=color:#f92672>.</span>newaxis])
</span></span></code></pre></div><h3 id=53-training-and-testing-an-svm>5.3 Training and testing an SVM</h3><p>After defining our SVM class we can train a model and test it on unseen examples.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Initialize a new SVM and train it on the given toy dataset</span>
</span></span><span style=display:flex><span>regularization_param <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>lr <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.000001</span>
</span></span><span style=display:flex><span>svm <span style=color:#f92672>=</span> LinearSVM(regularization_param)
</span></span><span style=display:flex><span>trained_weights <span style=color:#f92672>=</span> svm<span style=color:#f92672>.</span>train(features_train, labels_train, n_epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>, learning_rate<span style=color:#f92672>=</span>lr)
</span></span></code></pre></div><pre><code>Epoch 1, cost: 28.999523042690537
Epoch 2, cost: 8.626987624824444
Epoch 3, cost: 3.8253539901075273
Epoch 4, cost: 2.4947875220684446
Epoch 5, cost: 1.9543704229309797
Epoch 6, cost: 1.5987135095492675
Epoch 7, cost: 1.3611077210579672
Epoch 8, cost: 1.1702119735961691
Epoch 9, cost: 1.0372585586110663
Epoch 10, cost: 0.9557095984777207
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Predict lables for unknown test samples</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.metrics <span style=color:#f92672>import</span> accuracy_score, recall_score, precision_score
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>predicted_labels <span style=color:#f92672>=</span> svm<span style=color:#f92672>.</span>predict(features_test)
</span></span><span style=display:flex><span>predicted_labels <span style=color:#f92672>=</span> predicted_labels<span style=color:#f92672>.</span>flatten()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Accuracy on test dataset: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(accuracy_score(labels_test, predicted_labels)))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Recall on test dataset: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(recall_score(labels_test, predicted_labels)))
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#34;Precision on test dataset: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(recall_score(labels_test, predicted_labels)))    
</span></span></code></pre></div><pre><code>Accuracy on test dataset: 1.0
Recall on test dataset: 1.0
Precision on test dataset: 1.0
</code></pre><h3 id=54-visualizing-the-decision-boundary>5.4 Visualizing the decision boundary</h3><p>Given our trained model we can visualize the decision boundary, as done below.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create dataset for visualization</span>
</span></span><span style=display:flex><span>size<span style=color:#f92672>=</span><span style=color:#ae81ff>40000</span>
</span></span><span style=display:flex><span>feat_1 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>uniform(low<span style=color:#f92672>=-</span><span style=color:#ae81ff>6</span>, high<span style=color:#f92672>=</span><span style=color:#ae81ff>7</span>, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>feat_2 <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>uniform(low<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>, high<span style=color:#f92672>=</span><span style=color:#ae81ff>13</span>, size<span style=color:#f92672>=</span>size)
</span></span><span style=display:flex><span>features_vis <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>column_stack((feat_1, feat_2))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>labels_vis <span style=color:#f92672>=</span> svm<span style=color:#f92672>.</span>predict(features_vis)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Plot the decision boundary</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>5</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(features_vis[:, <span style=color:#ae81ff>0</span>], features_vis[:, <span style=color:#ae81ff>1</span>], c <span style=color:#f92672>=</span> labels_vis)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;SVM decision boundary&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Feature 2&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Feature 1&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><img src=/posts/machine_learning/images/svm_decision_boundary.png width=55% class=center><h2 id=6-dual-approach>6. Dual approach</h2><p>In the previous sections we took a detailed look at the primal SVM. To solve a primal SVM, we need to find the best values for the weights and bias. Recall that our input examples $\mathbf{x} \in \mathbb{R}^D$ have $D$ features. Consequently, our weights $\mathbf{w}$ have $D$ features, too. This can become problematic if the number of features $D$ is large.</p><p>That&rsquo;s where the second way of formalizing SVMs (called <em>dual approach</em>) comes in handy. The optimization problem of the dual approach is independent of the number of features. Instead, the number of parameters increases with the number of examples in the training set.</p><p>The dual approach uses the method of Lagrange multipliers. Lagrange multipliers allow us to find the minimum or maximum of a function if there are one or more constraints on the input values we are allowed to used.</p><p>If you never heard of Lagrange multipliers I can recommend the <a href=https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint target=_blank rel=noopener>blog posts</a> and <a href="https://www.youtube.com/watch?v=yuqB-d5MjZA&amp;list=PLCg2-CTYVrQvNGLbd-FN70UxWZSeKP4wV&amp;index=1" target=_blank rel=noopener>video tutorials</a> on the topic from Khan Academy.</p><h3 id=61-recap-lagrange-multipliers>6.1 Recap Lagrange multipliers</h3><p>Lagrange multipliers allow us to solve constrained optimization problems. Let&rsquo;s say we want to maximize the function $f(x, y) = 2x + y$ under the constraint that our values of $x$ and $y$ satisfy the following equation: $g(x, y) = x^2 + y^2 = 1$. This constraint equation describes a circle of radius 1.</p><p>The key insight behind the solution to this problem is that we need to find those values for $x$ and $y$ where the gradients of $f$ and $g$ are aligned. This can be expressed using a Lagrange multiplier (typically $\lambda$):</p><p>We want to find those values $x_m, y_m$ where $\nabla f(x_m, y_m) = \lambda \nabla g(x_m, y_m)$.</p><p>In our example the gradient vectors look as follows:
$$ \nabla f(x, y)=\left[\begin{array}{c}
\frac{\partial}{\partial x}(2 x+y) \\\
\frac{\partial}{\partial y}(2 x+y)
\end{array}\right]=\left[\begin{array}{c}
2 \\\ 1
\end{array}\right]$$</p><p>$$ \nabla g(x, y)=\left[\begin{array}{c}
\frac{\partial}{\partial x}\left(x^{2}+y^{2}-1\right) \\\
\frac{\partial}{\partial y}\left(x^{2}+y^{2}-1\right)
\end{array}\right]=\left[\begin{array}{c}
2 x \\\ 2 y
\end{array}\right]$$</p><p>Therefore, the tangency condition results in
$$ \left[\begin{array}{l}
2 \\\ 1
\end{array}\right]=\lambda \left[\begin{array}{l}
2 x_{m} \\\ 2 y_{m}
\end{array}\right] $$</p><p>We can rewrite the vector form into individual equations that can be solved by hand:</p><ul><li>$2 = \lambda 2 x_m $</li><li>$1 = \lambda 2 y_m $</li><li>$x_m^2 + y_m^2 = 1 $</li></ul><p>Solving the equations yields
$$ \begin{aligned}
\left(x_{0}, y_{0}\right) &=\left(\frac{1}{\lambda_{0}}, \frac{1}{2 \lambda_{0}}\right) \\\
&=\left(\frac{2}{\sqrt{5}}, \frac{1}{\sqrt{5}}\right) \quad \text { or } \quad\left(\frac{-2}{\sqrt{5}}, \frac{-1}{\sqrt{5}}\right)
\end{aligned} $$</p><p>where the first point denotes a maximum (what we wanted to find) and the second a minimum. This solves our constrained optimization problem. For more details and a full solution look at <a href=https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint target=_blank rel=noopener>this Khan academy post</a>.</p><h3 id=62-recap-lagrangian>6.2 Recap Lagrangian</h3><p>The Lagrangian is a way to repackage the individual conditions of our constrained optimization problem into a single equation. In the example above we wanted to optimize some function $f(x, y)$ under the constraint that the inputs $x$ and $y$ satisfy the equation $g(x, y) = x^2 + y^2 = c$. In our case the constant $c$ was given by 1. We know that the solution is given by those points where the gradients of $f$ and $g$ align. The Lagrangian function puts all of this into a single equation:</p><p>$$ \mathcal{L}(x, y, \lambda)=f(x, y)-\lambda(g(x, y)-c) $$</p><p>When computing the partial derivatives of $\mathcal{L}$ with respect to $x, y$ and $\lambda$ and setting them to zero, we will find that they correspond exactly to the three constraints we looked at earlier. This can be summarized by simply setting the gradient of $\mathcal{L}$ equal to the zero vector: $\nabla \mathcal{L} = \mathbf{0}$. The compact Lagrangian form is often used when solving constrained optimization problem with computers because it summarizes the elaborate problem with multiple constraints into a single equation. For more details and a full solution look at <a href=https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint target=_blank rel=noopener>this Khan academy post</a>.</p><h3 id=63-dual-optimization-problem>6.3 Dual optimization problem</h3><p>For the primal soft-margin SVM we considered the following optimization problem:
$$ \min_{\mathbf{w}, b, \mathbf{\xi}} \frac{1}{2} \Vert \mathbf{w} \Vert^2 + C \sum_{n=1}^N \xi_n $$</p><p>$$ \text{subject to:} $$</p><p>$$ y_n(\langle \mathbf{w}, \mathbf{x}_n \rangle + b) \ge 1 - \xi_n $$</p><p>$$ \xi_i \gt 0 \text{ for all } n = 1, &mldr;, N $$</p><p>To derive the corresponding Lagrangian we will introduce two Lagrange multipliers: $\alpha_n$ for the first constraint (that all examples are classified correctly) and $\lambda_n$ for the second constraint (non-negativity of the slack variables). The Lagrangian is then given by:</p><p>$$
\begin{aligned}
\mathfrak{L}(\boldsymbol{w}, b, \xi, \alpha, \gamma)=& \frac{1}{2}|\boldsymbol{w}|^{2}+C \sum_{n=1}^{N} \xi_{n} \\\
& \underbrace{-\sum_{n=1}^{N} \alpha_{n}\left(y_{n}\left(\left\langle\boldsymbol{w}, \boldsymbol{x}_{n}\right\rangle+b\right)-1+\xi_{n}\right)}_{\text{first constraint}} \underbrace{-\sum_{n=1}^{N} \gamma_{n} \xi_{n}}_{\text{second constraint}}
\end{aligned}
$$</p><p>Next, we have to compute the partial derivatives of the Lagrangian with respect to the variables $\mathbf{w}, b$ and $\xi$: $\frac{\partial \mathfrak{L}}{\partial \mathbf{w}}, \frac{\partial \mathfrak{L}}{\partial b}, \frac{\partial \mathfrak{L}}{\partial \xi}$. When setting the first partial derivative to zero we obtain an important interim result:
$$ \mathbf{w} = \sum_{n=1}^N \alpha_n y_n \mathbf{x}_n $$</p><p>This equation states the the optimal solution for the weight vector is given by a linear combination of our training examples. After setting the other partial derivatives to zero, using the result and simplifying the equations we end up with the following optimization problem (for details see section 12.3.1 of the <a href=https://mml-book.com target=_blank rel=noopener>Mathematics for Machine Learning book</a>):</p><p>$$\min_{\boldsymbol{\alpha}} \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^{N} y_{i} y_{j} \alpha_{i} \alpha_{j}\left\langle\mathbf{x}_{i}, \mathbf{x}_{j}\right\rangle-\sum_{i=1}^{N} \alpha_{i}$$
$$ \text{subject to:} $$
$$\sum_{i=1}^{N} y_{i} \alpha_{i}=0$$
$$0 \le \alpha_{i} \le C \text{ for all } i=1, \ldots, N$$</p><p>This constrained quadratic optimization problem can be solved very efficiently, for example with quadratic programming techniques. One popular library for solving dual SVMs is <a href=https://github.com/cjlin1/libsvm target=_blank rel=noopener>libsvm</a> which makes use of a decomposition method to solve the problem (see <a href=https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf target=_blank rel=noopener>this paper</a> for more details). However, several other approaches exist.</p><h2 id=7-primal-vs-dual-approach>7. Primal vs. dual approach</h2><p>Most SVM research in the last decade has been about the dual formulation. Why this is the case is not clear. Both approaches have advantages and disadvantages. In the paper <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.3368&amp;rep=rep1&amp;type=pdf" target=_blank rel=noopener>&ldquo;Training a Support Vector Machine in the Primal&rdquo;</a> Chapelle et al. mention the following hypothesis:</p><blockquote><p>We believe that it is because SVMs were first introduced in their hard margin formulation (Boser et al., 1992), for which a dual optimization (because of the constraints) seems more natural. In general, however, soft margin SVMs should be preferred, even if the training data are separable: the decision boundary is more robust because more training points are taken into account (Chapelle et al., 2000). We do not pretend that primal optimization is better in general; our main motivation wasto point out that primal and dual are two sides of the same coin and that there is no reason to look always at the same side.</p></blockquote><h2 id=8-kernels--non-linear-svm>8. Kernels / non-linear SVM</h2><h3 id=81-what-is-a-kernel>8.1 What is a kernel?</h3><p>If you take another look at the optimization equation of dual SVMs you will notice that it computes the inner product $\left\langle\mathbf{x}_{i}, \mathbf{x}_{j}\right\rangle$ between all datapoints $\mathbf{x}_{i}, \mathbf{x}_{j}$. A kernel is a way to compute this inner product implicitely in some (potentially very high dimensional) feature space. To be more precise: assume we have some mapping function $\varphi$ which maps an $n$ dimensional input vector to an $m$ dimensional output vector: $\varphi , : , \mathbb R^n \to \mathbb R^m$. Given this mapping function we can compute the dot product of two vectors $\mathbf x$ and $\mathbf y$ in this space as follows: $\varphi(\mathbf x)^T \varphi(\mathbf y)$.</p><p>A kernel is a function $k$ that gives the same result as this dot product: $k(\mathbf x, \mathbf y) = \varphi(\mathbf x)^T \varphi(\mathbf y)$. In other words: the kernel function is equivalent to the dot product of the mapping function.</p><h3 id=82-what-are-kernels-good-for>8.2 What are kernels good for?</h3><p>Until now (apart from the soft-margin SVM) our SVMs, both primal and dual, are only able to classify data that is <a href=https://en.wikipedia.org/wiki/Linear_separability target=_blank rel=noopener>linearly separable</a>. However, most datasets in practice won&rsquo;t be of this form. We need a way to classify data that is <strong>not</strong> linearly separable. This is where the so called <strong>kernel trick</strong> comes into play.</p><p>Because the objective function of the dual SVM contains inner products only between datapoints $\mathbf{x}_i, \mathbf{x}_j$, we can easily replace this inner product (that is, $\left\langle\mathbf{x}_{i}, \mathbf{x}_{j}\right\rangle$ ) with some mapping function $\varphi(\mathbf{x}_i)^T \varphi(\mathbf{x}_j)$. This mapping function can be non-linear, allowing us to compute an SVM that is non-linear with respect to the input examples. The mapping function takes our input data (which is not linearly separable) and transforms it into some higher-dimensional space where it becomes linearly separable. This is illustrated in the figure below.</p><img src=/posts/machine_learning/images/feature_mapping_illustration.png width=60% class=center><p>In theory, we could use any mapping function we like. In practice, however, computing inner products is expensive. Therefore, we use mapping functions that have a corresponding kernel function. This will allow us to map the datapoints into a higher dimensional space without ever explicitely computing the (expensive) inner products.</p><p>Let&rsquo;s take a look at an example.</p><h3 id=83-example>8.3 Example</h3><p>Note: this example was taken from <a href=https://stats.stackexchange.com/posts/153134 target=_blank rel=noopener>this StackExchange post</a>.</p><p>We can create a simple polynomial kernel as follows: $k(\mathbf{x}, \mathbf{y}) = (1 + \mathbf x^T \mathbf y)^2$ with $\mathbf x, \mathbf y \in \mathbb R^2$. The kernel does not seem to correspond to any mapping function $\varphi$, it&rsquo;s just a function that returns a real number. Our input vectors $\mathbf{x}, \mathbf{y}$ are 2-dimensional: $\mathbf x = (x_1, x_2)$ and $\mathbf y = (y_1, y_2)$. With this knowledge we can expand the kernel computation:</p><p>$\begin{align}
k(\mathbf x, \mathbf y) & = (1 + \mathbf x^T \mathbf y)^2 \\\
&= (1 + x_1 , y_1 + x_2 , y_2)^2 \\\
& = 1 + x_1^2 y_1^2 + x_2^2 y_2^2 + 2 x_1 y_1 + 2 x_2 y_2 + 2 x_1 x_2 y_1 y_2
\end{align}$</p><p>Note that this is nothing else but a dot product between two vectors $(1, x_1^2, x_2^2, \sqrt{2} x_1, \sqrt{2} x_2, \sqrt{2} x_1 x_2)$ and $(1, y_1^2, y_2^2, \sqrt{2} y_1, \sqrt{2} y_2, \sqrt{2} y_1 y_2)$. This can be expressed with the following mapping function:
$$\varphi(\mathbf x) = \varphi(x_1, x_2) = (1, x_1^2, x_2^2, \sqrt{2} x_1, \sqrt{2} x_2, \sqrt{2} x_1 x_2)$$</p><p>So the kernel $k(\mathbf x, \mathbf y) = (1 + \mathbf x^T \mathbf y)^2 = \varphi(\mathbf x)^T \varphi(\mathbf y)$ computes a dot product in 6-dimensional space without explicitly visiting this space. The generalization from an inner product to a kernel function is known as the <strong>kernel trick</strong>.</p><p>Several popular kernel functions exist. Popular ones are, for example, the <a href=https://en.wikipedia.org/wiki/Polynomial_kernel target=_blank rel=noopener>polyomial kernel</a> or <a href=https://en.wikipedia.org/wiki/Radial_basis_function_kernel target=_blank rel=noopener>RBF kernel</a>.</p><h3 id=84-can-we-also-use-kernels-in-the-primal-svm>8.4 Can we also use kernels in the primal SVM?</h3><p>Yes, the kernel trick can be applied to primal SVM&rsquo;s, too. It&rsquo;s not as straightforward as with dual SVMs but still possible. Consider <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.3368&amp;rep=rep1&amp;type=pdf" target=_blank rel=noopener>this paper by Chapelle et al.</a> as an example.</p><h3 id=85-how-do-i-choose-the-right-kernel-for-my-problem>8.5 How do I choose the right kernel for my problem?</h3><p>The problem of choosing the right kernel has been answered in <a href=https://stats.stackexchange.com/questions/18030/how-to-select-kernel-for-svm target=_blank rel=noopener>this StackExchange post</a>.</p><p>Summary:</p><ul><li>Without expert knowledge, the Radial Basis Function kernel makes a good default kernel (in case you need a non-linear model)</li><li>The choice of the kernel and parameters can be automated by optimising a cross-validation based model selection</li><li>Choosing the kernel and parameters automatically is tricky, as it is very easy to overfit the model selection criterion</li></ul><h2 id=9-sources-and-further-reading>9. Sources and further reading</h2><p>The basis for this notebook is chapter 12 of the book <a href=https://mml-book.github.io/ target=_blank rel=noopener>Mathematics for Machine Learning</a>. I can highly recommend to read through the entire chapter to get a deeper understanding of support vector machines.</p><p>Another source I liked very much is <a href="https://www.youtube.com/watch?v=_PwhiWxHK8o" target=_blank rel=noopener>this MIT lecture on SVMs</a>.</p></div><div class="row ps-3 pe-3"><div class="col-md-6 share-buttons"></div><div class="col-md-6 btn-improve-page"><a href=https://github.com/zotroneneis/zotroneneis.github.io/edit/main/content/posts/machine_learning/support_vector_machines.md title="Improve this page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>
Improve this page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/machine_learning/principal_component_analysis/ title="Principal component analysis (PCA)" class="btn filled-button"><div><i class="fas fa-chevron-circle-left"></i> Prev</div><div class=next-prev-text>Principal component analysis (PCA)</div></a></div><div class="col-md-6 next-article"><a href=/posts/machine_learning/variational_inference/ title="Variational Inference" class="btn filled-button"><div>Next <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Variational Inference</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn type=button data-bs-toggle=tooltip data-bs-placement=left title="Scroll to top"><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center ps-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#1-what-are-support-vector-machines>1. What are support vector machines?</a></li><li><a href=#2-primal-approach---hard-margin-svm>2. Primal approach - Hard-margin SVM</a><ul><li><a href=#21-goal-1>2.1 Goal 1</a></li><li><a href=#22-goal-2>2.2 Goal 2</a></li><li><a href=#23-combined-goal>2.3 Combined goal</a></li><li><a href=#24-optional-deriving-the-margin-equation>2.4 (Optional) Deriving the margin equation</a></li></ul></li><li><a href=#3-primal-approach---soft-margin-svm>3. Primal approach - Soft-margin SVM</a></li><li><a href=#4-solving-the-primal-optimization-problem>4. Solving the primal optimization problem</a><ul><li><a href=#41-hinge-loss-function>4.1 Hinge loss function</a></li><li><a href=#42-updated-objective-function>4.2 Updated objective function</a></li><li><a href=#43-optional-three-parts-of-the-objective-function>4.3 [Optional] Three parts of the objective function</a></li><li><a href=#44-sub-gradient-descent>4.4 Sub-gradient descent</a></li><li><a href=#45-optional-difference-subgradient-descent-and-gradient-descent>4.5 [Optional] Difference subgradient descent and gradient descent</a><ul><li><a href=#451-what-is-a-subgradient>4.5.1 What is a subgradient?</a></li><li><a href=#452-subgradient-method>4.5.2 Subgradient method</a></li></ul></li></ul></li><li><a href=#5-implementation-primal-approach>5. Implementation primal approach</a><ul><li><a href=#51-toy-dataset>5.1 Toy dataset</a></li><li><a href=#52-svm-class-definition>5.2 SVM class definition</a></li><li><a href=#53-training-and-testing-an-svm>5.3 Training and testing an SVM</a></li><li><a href=#54-visualizing-the-decision-boundary>5.4 Visualizing the decision boundary</a></li></ul></li><li><a href=#6-dual-approach>6. Dual approach</a><ul><li><a href=#61-recap-lagrange-multipliers>6.1 Recap Lagrange multipliers</a></li><li><a href=#62-recap-lagrangian>6.2 Recap Lagrangian</a></li><li><a href=#63-dual-optimization-problem>6.3 Dual optimization problem</a></li></ul></li><li><a href=#7-primal-vs-dual-approach>7. Primal vs. dual approach</a></li><li><a href=#8-kernels--non-linear-svm>8. Kernels / non-linear SVM</a><ul><li><a href=#81-what-is-a-kernel>8.1 What is a kernel?</a></li><li><a href=#82-what-are-kernels-good-for>8.2 What are kernels good for?</a></li><li><a href=#83-example>8.3 Example</a></li><li><a href=#84-can-we-also-use-kernels-in-the-primal-svm>8.4 Can we also use kernels in the primal SVM?</a></li><li><a href=#85-how-do-i-choose-the-right-kernel-for-my-problem>8.5 How do I choose the right kernel for my problem?</a></li></ul></li><li><a href=#9-sources-and-further-reading>9. Sources and further reading</a></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=https://alpopkes.com/#appearances>Talks & Podcasts</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:popkes@gmx.net target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>popkes@gmx.net</span></a></li><li><a href=https://github.com/zotroneneis target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>zotroneneis</span></a></li></ul></div></div></div><hr><div class=container><div class="row text-start"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu16779671404603505019.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center"> 2020-2021 Copyright.</div><div class="col-md-4 text-end"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.d7aab8398181e71632b7543a04f74db83c8a6210962005e5d34884b8613a8404.js integrity="sha256-16q4OYGB5xYyt1Q6BPdNuDyKYhCWIAXl00iEuGE6hAQ=" defer></script></body></html>